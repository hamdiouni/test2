{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Network Telemetry Simulation\n",
    "\n",
    "This notebook simulates real-time network telemetry data and sends it to the SLA Prediction Platform API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "API_BASE_URL = \"http://localhost:8000\"\n",
    "PREDICT_ENDPOINT = f\"{API_BASE_URL}/predict-and-store/\"\n",
    "ANOMALY_ENDPOINT = f\"{API_BASE_URL}/anomaly/\"\n",
    "\n",
    "# Simulation parameters\n",
    "SIMULATION_DURATION = 300  # seconds\n",
    "UPDATE_INTERVAL = 5  # seconds\n",
    "BURST_PROBABILITY = 0.1  # Probability of network burst\n",
    "ANOMALY_PROBABILITY = 0.05  # Probability of anomaly\n",
    "\n",
    "# Network nodes\n",
    "NODES = ['S1', 'S2', 'S3']\n",
    "NODE_PAIRS = [('S1', 'S2'), ('S1', 'S3'), ('S2', 'S3')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telemetry Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkTelemetryGenerator:\n",
    "    \"\"\"Generate realistic network telemetry data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.baseline_metrics = {\n",
    "            'bandwidth': 2.0,\n",
    "            'throughput': 2.0,\n",
    "            'congestion': 5.0,\n",
    "            'packet_loss': 0.5,\n",
    "            'latency': 8.0,\n",
    "            'jitter': 0.5\n",
    "        }\n",
    "        self.time_step = 0\n",
    "    \n",
    "    def generate_normal_telemetry(self, source: str, target: str) -> Dict:\n",
    "        \"\"\"Generate normal network telemetry\"\"\"\n",
    "        # Add time-based variations\n",
    "        time_factor = np.sin(self.time_step * 0.1) * 0.2 + 1\n",
    "        \n",
    "        # Base metrics with some randomness\n",
    "        telemetry = {\n",
    "            'bandwidth': self.baseline_metrics['bandwidth'] * time_factor + np.random.normal(0, 0.2),\n",
    "            'throughput': self.baseline_metrics['throughput'] * time_factor + np.random.normal(0, 0.3),\n",
    "            'congestion': max(0, self.baseline_metrics['congestion'] + np.random.normal(0, 2)),\n",
    "            'packet_loss': max(0, self.baseline_metrics['packet_loss'] + np.random.normal(0, 0.5)),\n",
    "            'latency': max(1, self.baseline_metrics['latency'] + np.random.normal(0, 1.5)),\n",
    "            'jitter': max(0, self.baseline_metrics['jitter'] + np.random.normal(0, 0.2)),\n",
    "            'network_measure': source,\n",
    "            'network_target': target,\n",
    "            'routers': 'up xrv6',\n",
    "            'planned_route': 'Best effort'\n",
    "        }\n",
    "        \n",
    "        # Ensure throughput doesn't exceed bandwidth\n",
    "        telemetry['throughput'] = min(telemetry['throughput'], telemetry['bandwidth'])\n",
    "        \n",
    "        return telemetry\n",
    "    \n",
    "    def generate_burst_telemetry(self, source: str, target: str) -> Dict:\n",
    "        \"\"\"Generate telemetry during network burst\"\"\"\n",
    "        telemetry = self.generate_normal_telemetry(source, target)\n",
    "        \n",
    "        # Increase congestion and latency during burst\n",
    "        telemetry['congestion'] *= np.random.uniform(3, 8)\n",
    "        telemetry['latency'] *= np.random.uniform(2, 5)\n",
    "        telemetry['packet_loss'] *= np.random.uniform(2, 10)\n",
    "        telemetry['jitter'] *= np.random.uniform(2, 4)\n",
    "        \n",
    "        # Reduce throughput\n",
    "        telemetry['throughput'] *= np.random.uniform(0.3, 0.7)\n",
    "        \n",
    "        return telemetry\n",
    "    \n",
    "    def generate_anomaly_telemetry(self, source: str, target: str) -> Dict:\n",
    "        \"\"\"Generate anomalous telemetry data\"\"\"\n",
    "        telemetry = self.generate_normal_telemetry(source, target)\n",
    "        \n",
    "        # Create different types of anomalies\n",
    "        anomaly_type = np.random.choice(['high_latency', 'packet_storm', 'jitter_spike', 'congestion_spike'])\n",
    "        \n",
    "        if anomaly_type == 'high_latency':\n",
    "            telemetry['latency'] *= np.random.uniform(5, 20)\n",
    "        elif anomaly_type == 'packet_storm':\n",
    "            telemetry['packet_loss'] *= np.random.uniform(10, 50)\n",
    "        elif anomaly_type == 'jitter_spike':\n",
    "            telemetry['jitter'] *= np.random.uniform(10, 30)\n",
    "        elif anomaly_type == 'congestion_spike':\n",
    "            telemetry['congestion'] = np.random.uniform(80, 100)\n",
    "        \n",
    "        return telemetry\n",
    "    \n",
    "    def generate_telemetry(self, source: str, target: str) -> Dict:\n",
    "        \"\"\"Generate telemetry based on current conditions\"\"\"\n",
    "        self.time_step += 1\n",
    "        \n",
    "        # Determine telemetry type\n",
    "        if np.random.random() < ANOMALY_PROBABILITY:\n",
    "            return self.generate_anomaly_telemetry(source, target)\n",
    "        elif np.random.random() < BURST_PROBABILITY:\n",
    "            return self.generate_burst_telemetry(source, target)\n",
    "        else:\n",
    "            return self.generate_normal_telemetry(source, target)\n",
    "\n",
    "# Initialize generator\n",
    "generator = NetworkTelemetryGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLAPlatformClient:\n",
    "    \"\"\"Client for SLA Prediction Platform API\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def predict_and_store(self, telemetry: Dict) -> Dict:\n",
    "        \"\"\"Send telemetry for prediction and storage\"\"\"\n",
    "        try:\n",
    "            response = self.session.post(\n",
    "                f\"{self.base_url}/predict-and-store/\",\n",
    "                json=telemetry,\n",
    "                timeout=10\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def detect_anomaly(self, telemetry: Dict) -> Dict:\n",
    "        \"\"\"Send telemetry for anomaly detection\"\"\"\n",
    "        try:\n",
    "            response = self.session.post(\n",
    "                f\"{self.base_url}/anomaly/\",\n",
    "                json=telemetry,\n",
    "                timeout=10\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Anomaly API Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def health_check(self) -> bool:\n",
    "        \"\"\"Check if API is healthy\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f\"{self.base_url}/health\", timeout=5)\n",
    "            return response.status_code == 200\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# Initialize client\n",
    "client = SLAPlatformClient(API_BASE_URL)\n",
    "\n",
    "# Check API health\n",
    "if client.health_check():\n",
    "    print(\"‚úÖ API is healthy and ready\")\n",
    "else:\n",
    "    print(\"‚ùå API is not available. Please start the backend service.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data storage for visualization\n",
    "simulation_data = []\n",
    "predictions = []\n",
    "anomalies = []\n",
    "\n",
    "def run_simulation_step():\n",
    "    \"\"\"Run one step of the simulation\"\"\"\n",
    "    timestamp = datetime.now()\n",
    "    \n",
    "    # Generate telemetry for each node pair\n",
    "    for source, target in NODE_PAIRS:\n",
    "        # Generate telemetry\n",
    "        telemetry = generator.generate_telemetry(source, target)\n",
    "        telemetry['timestamp'] = timestamp.isoformat()\n",
    "        \n",
    "        # Store for visualization\n",
    "        simulation_data.append(telemetry.copy())\n",
    "        \n",
    "        # Send to API for prediction\n",
    "        prediction_result = client.predict_and_store(telemetry)\n",
    "        if prediction_result:\n",
    "            prediction_result['timestamp'] = timestamp\n",
    "            prediction_result['source'] = source\n",
    "            prediction_result['target'] = target\n",
    "            predictions.append(prediction_result)\n",
    "            \n",
    "            print(f\"üìä {source}‚Üí{target}: SLA Risk {prediction_result.get('sla_violation', 'N/A')}\")\n",
    "        \n",
    "        # Check for anomalies\n",
    "        anomaly_result = client.detect_anomaly(telemetry)\n",
    "        if anomaly_result and anomaly_result.get('is_anomaly'):\n",
    "            anomaly_result['timestamp'] = timestamp\n",
    "            anomaly_result['source'] = source\n",
    "            anomaly_result['target'] = target\n",
    "            anomaly_result.update(telemetry)\n",
    "            anomalies.append(anomaly_result)\n",
    "            \n",
    "            print(f\"üö® ANOMALY {source}‚Üí{target}: {anomaly_result.get('explanation', 'Unknown')}\")\n",
    "\n",
    "# Run simulation\n",
    "print(f\"üöÄ Starting {SIMULATION_DURATION}s simulation with {UPDATE_INTERVAL}s intervals...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "step = 0\n",
    "\n",
    "while time.time() - start_time < SIMULATION_DURATION:\n",
    "    step += 1\n",
    "    print(f\"\\n‚è±Ô∏è  Step {step} - {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    run_simulation_step()\n",
    "    \n",
    "    # Wait for next interval\n",
    "    time.sleep(UPDATE_INTERVAL)\n",
    "\n",
    "print(\"\\n‚úÖ Simulation completed!\")\n",
    "print(f\"üìà Generated {len(simulation_data)} telemetry records\")\n",
    "print(f\"üîÆ Made {len(predictions)} predictions\")\n",
    "print(f\"üö® Detected {len(anomalies)} anomalies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrames\n",
    "df_telemetry = pd.DataFrame(simulation_data)\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "df_anomalies = pd.DataFrame(anomalies)\n",
    "\n",
    "print(f\"Telemetry records: {len(df_telemetry)}\")\n",
    "print(f\"Predictions: {len(df_predictions)}\")\n",
    "print(f\"Anomalies: {len(df_anomalies)}\")\n",
    "\n",
    "# Display basic statistics\n",
    "if not df_telemetry.empty:\n",
    "    print(\"\\nTelemetry Statistics:\")\n",
    "    print(df_telemetry[['latency', 'throughput', 'packet_loss', 'jitter']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Network Telemetry Analysis', fontsize=16)\n",
    "\n",
    "if not df_telemetry.empty:\n",
    "    # Latency over time\n",
    "    axes[0, 0].plot(df_telemetry.index, df_telemetry['latency'], 'b-', alpha=0.7)\n",
    "    axes[0, 0].axhline(y=10, color='r', linestyle='--', label='SLA Threshold')\n",
    "    axes[0, 0].set_title('Network Latency')\n",
    "    axes[0, 0].set_ylabel('Latency (ms)')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Throughput vs Bandwidth\n",
    "    axes[0, 1].scatter(df_telemetry['bandwidth'], df_telemetry['throughput'], alpha=0.6)\n",
    "    axes[0, 1].plot([0, df_telemetry['bandwidth'].max()], [0, df_telemetry['bandwidth'].max()], 'r--', label='Ideal')\n",
    "    axes[0, 1].set_title('Throughput vs Bandwidth')\n",
    "    axes[0, 1].set_xlabel('Bandwidth (Mbps)')\n",
    "    axes[0, 1].set_ylabel('Throughput (Mbps)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Packet Loss Distribution\n",
    "    axes[1, 0].hist(df_telemetry['packet_loss'], bins=20, alpha=0.7, color='orange')\n",
    "    axes[1, 0].axvline(x=5, color='r', linestyle='--', label='Threshold')\n",
    "    axes[1, 0].set_title('Packet Loss Distribution')\n",
    "    axes[1, 0].set_xlabel('Packet Loss (%)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Network Congestion\n",
    "    axes[1, 1].plot(df_telemetry.index, df_telemetry['congestion'], 'g-', alpha=0.7)\n",
    "    axes[1, 1].axhline(y=50, color='orange', linestyle='--', label='Warning')\n",
    "    axes[1, 1].axhline(y=80, color='r', linestyle='--', label='Critical')\n",
    "    axes[1, 1].set_title('Network Congestion')\n",
    "    axes[1, 1].set_ylabel('Congestion (%)')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLA Violation Analysis\n",
    "if not df_predictions.empty:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # SLA Violations over time\n",
    "    sla_violations = [p.get('sla_violation', 0) for p in predictions]\n",
    "    axes[0].plot(range(len(sla_violations)), sla_violations, 'ro-', alpha=0.7)\n",
    "    axes[0].set_title('SLA Violations Over Time')\n",
    "    axes[0].set_ylabel('SLA Violation (0/1)')\n",
    "    axes[0].set_xlabel('Prediction Step')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # SLA Violation Rate by Connection\n",
    "    if 'source' in df_predictions.columns and 'target' in df_predictions.columns:\n",
    "        connection_violations = df_predictions.groupby(['source', 'target'])['sla_violation'].mean()\n",
    "        connection_violations.plot(kind='bar', ax=axes[1], color='coral')\n",
    "        axes[1].set_title('SLA Violation Rate by Connection')\n",
    "        axes[1].set_ylabel('Violation Rate')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    total_predictions = len(predictions)\n",
    "    total_violations = sum(sla_violations)\n",
    "    violation_rate = (total_violations / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä SLA Analysis Summary:\")\n",
    "    print(f\"Total Predictions: {total_predictions}\")\n",
    "    print(f\"SLA Violations: {total_violations}\")\n",
    "    print(f\"Violation Rate: {violation_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Analysis\n",
    "if not df_anomalies.empty:\n",
    "    print(f\"\\nüö® Anomaly Analysis:\")\n",
    "    print(f\"Total Anomalies Detected: {len(df_anomalies)}\")\n",
    "    \n",
    "    # Anomaly types\n",
    "    if 'explanation' in df_anomalies.columns:\n",
    "        print(\"\\nAnomaly Types:\")\n",
    "        for explanation in df_anomalies['explanation'].unique():\n",
    "            count = (df_anomalies['explanation'] == explanation).sum()\n",
    "            print(f\"  - {explanation}: {count}\")\n",
    "    \n",
    "    # Plot anomaly scores\n",
    "    if 'anomaly_score' in df_anomalies.columns:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.hist(df_anomalies['anomaly_score'], bins=10, alpha=0.7, color='red')\n",
    "        plt.title('Anomaly Score Distribution')\n",
    "        plt.xlabel('Anomaly Score')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\nelse:\n",
    "    print(\"\\n‚úÖ No anomalies detected during simulation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export simulation results\n",
    "timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "if not df_telemetry.empty:\n",
    "    df_telemetry.to_csv(f'simulation_telemetry_{timestamp_str}.csv', index=False)\n",
    "    print(f\"üìÅ Exported telemetry data to simulation_telemetry_{timestamp_str}.csv\")\n",
    "\n",
    "if not df_predictions.empty:\n",
    "    df_predictions.to_csv(f'simulation_predictions_{timestamp_str}.csv', index=False)\n",
    "    print(f\"üìÅ Exported predictions to simulation_predictions_{timestamp_str}.csv\")\n",
    "\n",
    "if not df_anomalies.empty:\n",
    "    df_anomalies.to_csv(f'simulation_anomalies_{timestamp_str}.csv', index=False)\n",
    "    print(f\"üìÅ Exported anomalies to simulation_anomalies_{timestamp_str}.csv\")\n",
    "\n",
    "# Create summary report\n",
    "summary = {\n",
    "    'simulation_duration': SIMULATION_DURATION,\n",
    "    'update_interval': UPDATE_INTERVAL,\n",
    "    'total_telemetry_records': len(simulation_data),\n",
    "    'total_predictions': len(predictions),\n",
    "    'total_anomalies': len(anomalies),\n",
    "    'sla_violation_rate': violation_rate if 'violation_rate' in locals() else 0,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(f'simulation_summary_{timestamp_str}.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"üìÅ Exported summary to simulation_summary_{timestamp_str}.json\")\n",
    "print(\"\\n‚úÖ Simulation complete! Check the exported files for detailed results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}